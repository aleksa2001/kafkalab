from kafka import KafkaConsumer, KafkaProducer
import json
from model import SentimentAnalyzer
import pandas as pd
from datetime import datetime
import time
import threading


class SentimentConsumer:
    def __init__(self, bootstrap_servers='localhost:9092', window_size=100):
        self.consumer = KafkaConsumer(
            'raw_reviews',
            bootstrap_servers=bootstrap_servers,
            auto_offset_reset='earliest',
            value_deserializer=lambda x: json.loads(x.decode('utf-8')),
            group_id='sentiment-analysis-group',
            enable_auto_commit=True
        )

        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')
        )

        self.model = SentimentAnalyzer()
        self.window_size = window_size
        self.processed_reviews = []
        self.statistics = {
            'total_processed': 0,
            'positive_count': 0,
            'negative_count': 0,
            'by_source': {},
            'by_location': {},
            'by_hour': {},
            'vader_accuracy': 0,
            'textblob_accuracy': 0,
            'ml_accuracy': 0,
            'avg_confidence': 0,
            'last_update': datetime.now().isoformat()
        }

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.initialize_model()

    def initialize_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        try:
            df = pd.read_csv('data/reviews_processed.csv')
            accuracy = self.model.train_ml_model(df)
            self.statistics['ml_accuracy'] = float(accuracy)
            print("‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –∏ –æ–±—É—á–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã (VADER, TextBlob)")

    def analyze_sentiment(self, text):
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –≤—Å–µ–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –º–µ—Ç–æ–¥
        sentiment, confidence = self.model.predict_ensemble(text)

        # –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤
        vader_sentiment, vader_conf = self.model.predict_vader(text)
        blob_sentiment, blob_conf = self.model.predict_textblob(text)
        ml_sentiment, ml_conf = self.model.predict_ml(text)

        return {
            'ensemble': {
                'sentiment': 'positive' if sentiment == 1 else 'negative',
                'confidence': confidence,
                'numeric': sentiment
            },
            'vader': {
                'sentiment': 'positive' if vader_sentiment == 1 else 'negative',
                'confidence': vader_conf,
                'numeric': vader_sentiment
            },
            'textblob': {
                'sentiment': 'positive' if blob_sentiment == 1 else 'negative',
                'confidence': blob_conf,
                'numeric': blob_sentiment
            },
            'ml': {
                'sentiment': 'positive' if ml_sentiment == 1 else 'negative',
                'confidence': ml_conf,
                'numeric': ml_sentiment
            }
        }

    def process_review(self, review):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–∞"""
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        sentiment_results = self.analyze_sentiment(review['text'])

        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        processed_review = {
            **review,
            'sentiment_analysis': sentiment_results,
            'processing_time': datetime.now().isoformat(),
            'processing_duration': (datetime.now() - datetime.fromisoformat(
                review.get('producer_time', datetime.now().isoformat()))).total_seconds()
        }

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.update_statistics(processed_review)

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ processed_reviews
        try:
            self.producer.send('processed_reviews', value=processed_review)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ processed_reviews: {e}")

        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {review['review_id']}")
        print(f"   –¢–µ–∫—Å—Ç: {review['text'][:60]}...")
        print(
            f"   –ê–Ω—Å–∞–º–±–ª—å: {sentiment_results['ensemble']['sentiment']} ({sentiment_results['ensemble']['confidence']:.2f})")
        print(f"   –ò—Å—Ç–∏–Ω–Ω–∞—è: {'positive' if review['true_sentiment'] == 1 else 'negative'}")

        return processed_review

    def update_statistics(self, review):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.statistics['total_processed'] += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        sentiment = review['sentiment_analysis']['ensemble']['numeric']
        if sentiment == 1:
            self.statistics['positive_count'] += 1
        else:
            self.statistics['negative_count'] += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É
        source = review['source']
        if source not in self.statistics['by_source']:
            self.statistics['by_source'][source] = {'positive': 0, 'negative': 0, 'total': 0}
        self.statistics['by_source'][source]['total'] += 1
        if sentiment == 1:
            self.statistics['by_source'][source]['positive'] += 1
        else:
            self.statistics['by_source'][source]['negative'] += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ª–æ–∫–∞—Ü–∏–∏
        location = review['location']
        if location not in self.statistics['by_location']:
            self.statistics['by_location'][location] = {'positive': 0, 'negative': 0, 'total': 0}
        self.statistics['by_location'][location]['total'] += 1
        if sentiment == 1:
            self.statistics['by_location'][location]['positive'] += 1
        else:
            self.statistics['by_location'][location]['negative'] += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å–∞–º
        try:
            hour = datetime.fromisoformat(str(review['timestamp'])).hour
            hour_key = f"{hour:02d}:00"
            if hour_key not in self.statistics['by_hour']:
                self.statistics['by_hour'][hour_key] = {'count': 0, 'positive': 0}
            self.statistics['by_hour'][hour_key]['count'] += 1
            if sentiment == 1:
                self.statistics['by_hour'][hour_key]['positive'] += 1
        except:
            pass

        # –†–∞—Å—á–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π (–µ—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–∏–Ω–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)
        true_sentiment = review.get('true_sentiment')
        if true_sentiment is not None:
            # VADER accuracy
            vader_correct = (review['sentiment_analysis']['vader']['numeric'] == true_sentiment)
            self.statistics['vader_accuracy'] = (
                    self.statistics.get('vader_accuracy', 0) * 0.9 + vader_correct * 0.1
            )

            # TextBlob accuracy
            blob_correct = (review['sentiment_analysis']['textblob']['numeric'] == true_sentiment)
            self.statistics['textblob_accuracy'] = (
                    self.statistics.get('textblob_accuracy', 0) * 0.9 + blob_correct * 0.1
            )

            # ML accuracy
            ml_correct = (review['sentiment_analysis']['ml']['numeric'] == true_sentiment)
            self.statistics['ml_accuracy'] = (
                    self.statistics.get('ml_accuracy', 0) * 0.9 + ml_correct * 0.1
            )

        # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence = review['sentiment_analysis']['ensemble']['confidence']
        self.statistics['avg_confidence'] = (
                self.statistics.get('avg_confidence', 0) * 0.9 + confidence * 0.1
        )

        self.statistics['last_update'] = datetime.now().isoformat()

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
        self.save_statistics()

    def save_statistics(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ JSON"""
        try:
            with open('data/statistics.json', 'w') as f:
                json.dump(self.statistics, f, indent=2, default=str)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

    def consume(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª consumption"""
        print("üöÄ Consumer –∑–∞–ø—É—â–µ–Ω –∏ –æ–∂–∏–¥–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è...")
        print("   –¢–æ–ø–∏–∫: raw_reviews")
        print("   –ì—Ä—É–ø–ø–∞: sentiment-analysis-group")
        print("-" * 50)

        try:
            for message in self.consumer:
                try:
                    review = message.value
                    self.process_review(review)

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ—Ç–∑—ã–≤–æ–≤
                    self.processed_reviews.append(review)
                    if len(self.processed_reviews) > self.window_size:
                        self.processed_reviews.pop(0)

                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                    continue

        except KeyboardInterrupt:
            print("\nüõë Consumer –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        finally:
            self.consumer.close()
            self.producer.close()


if __name__ == "__main__":
    consumer = SentimentConsumer()
    consumer.consume()