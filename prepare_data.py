import pandas as pd
import numpy as np
import re
from nltk.corpus import stopwords
import nltk
from datetime import datetime

# –°–∫–∞—á–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã NLTK
import ssl

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

nltk.download('stopwords', quiet=True)
nltk.download('vader_lexicon', quiet=True)


def clean_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ –≤–∞—à–µ–≥–æ notebook)"""
    if pd.isna(text):
        return ""

    text = str(text).lower()
    # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    text = text.replace('"', '').replace("'", "")
    text = re.sub(r"[^\w\s]", " ", text)

    # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    STOPWORDS = set(stopwords.words("english"))
    text = ' '.join([w for w in text.split() if w not in STOPWORDS])

    return text.strip()


def prepare_dataset():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Kafka pipeline"""

    # –ß–∏—Ç–∞–µ–º CSV —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–∞–≤—ã—á–µ–∫
    df = pd.read_csv(
        'data/sentiment-analysis.csv',
        quotechar='"',
        sep=","
    )

    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤ –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ, —Ä–∞–∑–¥–µ–ª—è–µ–º –∏—Ö
    if df.shape[1] == 1:
        df = df.iloc[:, 0].str.split(',', expand=True)
        df.columns = ['Text', 'Sentiment', 'Source', 'Date/Time', 'User ID', 'Location', 'Confidence Score']

    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = df.dropna(subset=['Text', 'Sentiment'])

    # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
    df['cleaned_text'] = df['Text'].apply(clean_text)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Sentiment –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
    sentiment_mapping = {
        'Positive': 1,
        'Negative': 0,
        ' Positive': 1,
        ' Negative': 0
    }

    df['sentiment_numeric'] = df['Sentiment'].map(sentiment_mapping)

    # –°–æ–∑–¥–∞–µ–º review_id –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
    df['review_id'] = [f'rev_{i:06d}' for i in range(len(df))]

    # –°–æ–∑–¥–∞–µ–º timestamp –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if 'Date/Time' in df.columns:
        df['timestamp'] = pd.to_datetime(df['Date/Time'], errors='coerce')
    else:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞—Ç—ã –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü
        end_date = datetime.now()
        start_date = end_date - pd.Timedelta(days=30)
        random_dates = pd.to_datetime(np.random.uniform(
            start_date.timestamp(),
            end_date.timestamp(),
            len(df)
        ), unit='s')
        df['timestamp'] = random_dates

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    if 'Source' not in df.columns:
        df['Source'] = 'Unknown'

    if 'Location' not in df.columns:
        df['Location'] = 'Unknown'

    if 'Confidence Score' not in df.columns:
        df['Confidence Score'] = np.random.uniform(0.6, 0.95, len(df))

    # –°–æ–∑–¥–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    df['rating'] = df['sentiment_numeric'].apply(
        lambda x: np.random.randint(4, 6) if x == 1 else np.random.randint(1, 3)
    )

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã
    df = df[df['cleaned_text'].str.len() > 10]

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    output_df = df[[
        'review_id',
        'Text',
        'cleaned_text',
        'sentiment_numeric',
        'Source',
        'Location',
        'Confidence Score',
        'timestamp',
        'rating'
    ]].copy()

    output_df.columns = [
        'review_id',
        'original_text',
        'text',
        'true_sentiment',
        'source',
        'location',
        'confidence_score',
        'timestamp',
        'rating'
    ]

    output_df.to_csv('data/reviews_processed.csv', index=False)
    print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(output_df)} –æ—Ç–∑—ã–≤–æ–≤")
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:")
    print(f"   –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ: {(output_df['true_sentiment'] == 1).sum()}")
    print(f"   –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ: {(output_df['true_sentiment'] == 0).sum()}")

    return output_df


if __name__ == "__main__":
    df = prepare_dataset()
    print("\n–ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π:")
    print(df[['review_id', 'text', 'true_sentiment', 'source']].head())